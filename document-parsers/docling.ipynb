{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docling documentation](https://ds4sd.github.io/docling/)   \n",
    "[Docling technical report](https://arxiv.org/abs/2408.09869)   \n",
    "[RAG with LlamaIndex](https://ds4sd.github.io/docling/examples/rag_llamaindex/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS GPU is enabled.\")\n",
    "else:\n",
    "    raise EnvironmentError(\n",
    "        \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"./data/UPA-5.0-Parking-Garage.pdf\"\n",
    "FIRST_10_PAGES = \"./data/report_10_page.pdf\"\n",
    "\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "reader = PdfReader(SOURCE)\n",
    "writer = PdfWriter()\n",
    "\n",
    "# Extract the first 10 pages\n",
    "for page_num in range(min(10, len(reader.pages))):\n",
    "    writer.add_page(reader.pages[page_num])\n",
    "\n",
    "# Save the extracted pages to a new PDF\n",
    "with open(FIRST_10_PAGES, 'wb') as output_pdf:\n",
    "    writer.write(output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF does not contain 24 pages.\n",
      "Page 24 has been saved to data/page_25.pdf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "# Define the source and output file paths\n",
    "SOURCE = SOURCE\n",
    "OUTPUT = Path(\"./data/page_25.pdf\")\n",
    "\n",
    "# Read the PDF file\n",
    "reader = PdfReader(SOURCE)\n",
    "writer = PdfWriter()\n",
    "\n",
    "# Ensure the requested page exists in the document\n",
    "if len(reader.pages) >= 24:\n",
    "    # Add page 24 (index 23 since it's 0-based)\n",
    "    writer.add_page(reader.pages[24])\n",
    "else:\n",
    "    print(\"The PDF does not contain 24 pages.\")\n",
    "\n",
    "# Save the extracted page to a new PDF file\n",
    "with OUTPUT.open('wb') as output_pdf:\n",
    "    writer.write(output_pdf)\n",
    "\n",
    "print(f\"Page 24 has been saved to {OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to markdown (default options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing first 10 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    }
   ],
   "source": [
    "converter = DocumentConverter()\n",
    "result = converter.convert(FIRST_10_PAGES)\n",
    "#print(result.document.export_to_markdown)\n",
    "# Save to markdown\n",
    "\n",
    "output_dir = Path(\"parsed-doc\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "doc_filename = Path(FIRST_10_PAGES).stem\n",
    "\n",
    "\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing just page 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentConverter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert the document\n",
    "#result = converter.convert(FIRST_10_PAGES)\n",
    "result = converter.convert(\"./data/page_24.pdf\")\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "doc_filename = Path(\".data/page_24.pdf\").stem\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoding the image from markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoded string\n",
    "encoded_string = \"/uni0043/uni0061/uni0072/uni0062/uni006F/uni006E/uni0020/uni0066/uni006F/uni006F/uni0074/uni0070/uni0072/uni0069/uni006E/uni0074/uni0020/uni0028/uni006B/uni0067/uni0043/uni004F/uniE0C0/uni0065/uni002F/uni0079/uni0065/uni0061/uni0072/uni0029\"\n",
    "# Decode the string\n",
    "def decode_unicode_string(encoded):\n",
    "    # Split the string by '/' and filter out empty parts\n",
    "    parts = [part for part in encoded.split(\"/\") if part.startswith(\"uni\")]\n",
    "    # Convert each Unicode point to a character\n",
    "    decoded = \"\".join([chr(int(part[3:], 16)) for part in parts])\n",
    "    return decoded\n",
    "\n",
    "# Get the decoded string\n",
    "decoded_string = decode_unicode_string(encoded_string)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to markdown (advanced options)\n",
    "- https://ds4sd.github.io/docling/usage/\n",
    "- https://ds4sd.github.io/docling/installation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "PdfPipelineOptions??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode, EasyOcrOptions, TesseractOcrOptions, OcrMacOptions\n",
    "from docling.datamodel.settings import settings\n",
    "\n",
    "output_dir = Path(\"parsed-doc-advanced\")\n",
    "\n",
    "IMAGE_RESOLUTION_SCALE = 2.0\n",
    "\n",
    "# Define pipeline options for PDF processing\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,  # Enable table structure detection\n",
    "    do_ocr=True,  # Enable OCR\n",
    "    # full page ocr and language selection\n",
    "    #ocr_options=EasyOcrOptions(force_full_page_ocr=True, lang=[\"en\"]),  # Use EasyOCR for OCR\n",
    "    ocr_options=TesseractOcrOptions(force_full_page_ocr=True, lang=[\"eng\"]),  # Uncomment to use Tesseract for OCR\n",
    "    #ocr_options = OcrMacOptions(force_full_page_ocr=True, lang=['en-US']),\n",
    "    table_structure_options=dict(\n",
    "        do_cell_matching=False,  # Use text cells predicted from table structure model\n",
    "        mode=TableFormerMode.ACCURATE  # Use more accurate TableFormer model\n",
    "    ),\n",
    "    generate_page_images=True,  # Enable page image generation\n",
    "    generate_picture_images=True,  # Enable picture image generation\n",
    "    images_scale=IMAGE_RESOLUTION_SCALE, # Set image resolution scale (scale=1 corresponds to a standard 72 DPI image)\n",
    ")\n",
    "\n",
    "# Initialize the DocumentConverter with the specified pipeline options\n",
    "doc_converter_global = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "tesserocr is not correctly installed. Please install it via `pip install tesserocr` to use this OCR engine. Note that tesserocr might have to be manually compiled for working with your Tesseract installation. The Docling documentation provides examples for it. Alternatively, Docling has support for other OCR engines. See the documentation: https://docling-project.github.io/docling/installation/",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/models/tesseract_ocr_model.py:67\u001b[39m, in \u001b[36mTesseractOcrModel.__init__\u001b[39m\u001b[34m(self, enabled, artifacts_path, options, accelerator_options)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtesserocr\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tesserocr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m settings.debug.profile_pipeline_timings = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert the document\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#result = doc_converter_global.convert(FIRST_10_PAGES)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#result = doc_converter_global.convert(SOURCE)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43mdoc_converter_global\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/UPA-5.0-Parking-Garage.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m output_dir.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#doc_filename = Path(FIRST_10_PAGES).stem\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#doc_filename = Path(FIRST_10_PAGES).stem\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28mself\u001b[39m.__pydantic_validator__.validate_python(pydantic_core.ArgsKwargs(args, kwargs))\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:227\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    218\u001b[39m ) -> ConversionResult:\n\u001b[32m    219\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    220\u001b[39m         source=[source],\n\u001b[32m    221\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         page_range=page_range,\n\u001b[32m    226\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:250\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    247\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    249\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:285\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    276\u001b[39m _log.info(\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:331\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    327\u001b[39m valid = (\n\u001b[32m    328\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    329\u001b[39m )\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:352\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_pipeline\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m, in_doc: InputDocument, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    350\u001b[39m ) -> ConversionResult:\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m in_doc.valid:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m         pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    354\u001b[39m             conv_res = pipeline.execute(in_doc, raises_on_error=raises_on_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/document_converter.py:314\u001b[39m, in \u001b[36mDocumentConverter._get_pipeline\u001b[39m\u001b[34m(self, doc_format)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_pipelines:\n\u001b[32m    311\u001b[39m     _log.info(\n\u001b[32m    312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialized_pipelines[cache_key] = \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    318\u001b[39m     _log.debug(\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReusing cached pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/pipeline/standard_pdf_pipeline.py:68\u001b[39m, in \u001b[36mStandardPdfPipeline.__init__\u001b[39m\u001b[34m(self, pipeline_options)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.keep_images = (\n\u001b[32m     61\u001b[39m         \u001b[38;5;28mself\u001b[39m.pipeline_options.generate_page_images\n\u001b[32m     62\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline_options.generate_picture_images\n\u001b[32m     63\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline_options.generate_table_images\n\u001b[32m     64\u001b[39m     )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.reading_order_model = ReadingOrderModel(options=ReadingOrderOptions())\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m ocr_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_ocr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m.build_pipe = [\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Pre-processing\u001b[39;00m\n\u001b[32m     72\u001b[39m     PagePreprocessingModel(\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     PageAssembleModel(options=PageAssembleOptions()),\n\u001b[32m     93\u001b[39m ]\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Picture description model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/pipeline/standard_pdf_pipeline.py:154\u001b[39m, in \u001b[36mStandardPdfPipeline.get_ocr_model\u001b[39m\u001b[34m(self, artifacts_path)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_ocr_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, artifacts_path: Optional[Path] = \u001b[38;5;28;01mNone\u001b[39;00m) -> BaseOcrModel:\n\u001b[32m    151\u001b[39m     factory = get_ocr_factory(\n\u001b[32m    152\u001b[39m         allow_external_plugins=\u001b[38;5;28mself\u001b[39m.pipeline_options.allow_external_plugins\n\u001b[32m    153\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mocr_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_ocr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/models/factories/base_factory.py:57\u001b[39m, in \u001b[36mBaseFactory.create_instance\u001b[39m\u001b[34m(self, options, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     56\u001b[39m     _cls = \u001b[38;5;28mself\u001b[39m._classes[\u001b[38;5;28mtype\u001b[39m(options)]\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._err_msg_on_class_not_found(options.kind))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Captuscode/document-parsers/.venv/lib/python3.11/site-packages/docling/models/tesseract_ocr_model.py:69\u001b[39m, in \u001b[36mTesseractOcrModel.__init__\u001b[39m\u001b[34m(self, enabled, artifacts_path, options, accelerator_options)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtesserocr\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(install_errmsg)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m     tesseract_version = tesserocr.tesseract_version()\n",
      "\u001b[31mImportError\u001b[39m: tesserocr is not correctly installed. Please install it via `pip install tesserocr` to use this OCR engine. Note that tesserocr might have to be manually compiled for working with your Tesseract installation. The Docling documentation provides examples for it. Alternatively, Docling has support for other OCR engines. See the documentation: https://docling-project.github.io/docling/installation/"
     ]
    }
   ],
   "source": [
    "# Enable the profiling to measure the time spent\n",
    "settings.debug.profile_pipeline_timings = True\n",
    "\n",
    "# Convert the document\n",
    "#result = doc_converter_global.convert(FIRST_10_PAGES)\n",
    "#result = doc_converter_global.convert(SOURCE)\n",
    "result = doc_converter_global.convert(\"./data/UPA-5.0-Parking-Garage.pdf\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "doc_filename = Path(\"./data/page_25.pdf\").stem\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "#md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "md_filename = output_dir / f\"{doc_filename}-with-images.md\"\n",
    "#result.document.save_as_markdown(md_filename) # just shows there is image at this point, <!-- image -->\n",
    "result.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED) # image is embedded with base64\n",
    "#result.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED) #artifacts folder is created with this\n",
    "\n",
    "_log.info(f\"Markdown content has been saved to {md_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "#conv_res = DocumentConverter().convert(FIRST_10_PAGES)\n",
    "#doc = conv_res.document\n",
    "\n",
    "chunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")  # set tokenizer as needed\n",
    "chunk_iter = chunker.chunk(result.document)\n",
    "\n",
    "# Convert the iterator to a list to count the chunks\n",
    "chunks = list(chunk_iter)\n",
    "num_chunks = len(chunks)\n",
    "\n",
    "# Print the number of chunks\n",
    "print(f\"The document has been divided into {num_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FAQs](https://ds4sd.github.io/docling/faq/)\n",
    "\n",
    "### [Command Line Syntaxes](https://ds4sd.github.io/docling/v2/#cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip show tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling data/page_24.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling images/caltrain_schedule.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling https://www.kone.es/Images/KONE%20Sustainability_tcm117-105566.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  View the base64 encoded image via this [link](https://codebeautify.org/base64-to-image-converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Base64 string (trim \"data:image/png;base64,\" if needed)\n",
    "base64_string = \"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\"\n",
    "\n",
    "# Decode the Base64 string\n",
    "image_data = base64.b64decode(base64_string)\n",
    "\n",
    "# Convert to an image and display\n",
    "image = Image.open(BytesIO(image_data))\n",
    "image.show()\n",
    "\n",
    "# Optionally save the image\n",
    "with open(\"decoded_image.png\", \"wb\") as file:\n",
    "    file.write(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base64 string (trim \"data:image/png;base64,\" if needed)\n",
    "base64_string = \"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\"\n",
    "\n",
    "# Decode the Base64 string\n",
    "image_data = base64.b64decode(base64_string)\n",
    "\n",
    "# Convert to an image and display\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Display the image inline\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanned pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling data/scanned-document.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = doc_converter_global.convert(\"./data/scanned-document.pdf\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "doc_filename = Path(\"./data/scanned-document.pdf\").stem\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import FigureElement, InputFormat, Table\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_doc_path = FIRST_10_PAGES\n",
    "output_dir = Path(\"scratch_image\")\n",
    "\n",
    "# Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n",
    "# will destroy them for cleaning up memory.\n",
    "# This is done by setting PdfPipelineOptions.images_scale, which also defines the scale of images.\n",
    "# scale=1 correspond of a standard 72 DPI image\n",
    "# The PdfPipelineOptions.generate_* are the selectors for the document elements which will be enriched\n",
    "# with the image field\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "pipeline_options.generate_page_images = True\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "doc_filename = conv_res.input.file.stem\n",
    "\n",
    "# Save page images\n",
    "for page_no, page in conv_res.document.pages.items():\n",
    "    page_no = page.page_no\n",
    "    page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"\n",
    "    with page_image_filename.open(\"wb\") as fp:\n",
    "        page.image.pil_image.save(fp, format=\"PNG\")\n",
    "\n",
    "# Save images of figures and tables\n",
    "table_counter = 0\n",
    "picture_counter = 0\n",
    "for element, _level in conv_res.document.iterate_items():\n",
    "    if isinstance(element, TableItem):\n",
    "        table_counter += 1\n",
    "        element_image_filename = (\n",
    "            output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
    "        )\n",
    "        with element_image_filename.open(\"wb\") as fp:\n",
    "            element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "    if isinstance(element, PictureItem):\n",
    "        picture_counter += 1\n",
    "        element_image_filename = (\n",
    "            output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
    "        )\n",
    "        with element_image_filename.open(\"wb\") as fp:\n",
    "            element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "md_filename = output_dir / f\"{doc_filename}-with-images.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED)\n",
    "\n",
    "# Save markdown with externally referenced pictures\n",
    "md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "# Save HTML with externally referenced pictures\n",
    "html_filename = output_dir / f\"{doc_filename}-with-image-refs.html\"\n",
    "conv_res.document.save_as_html(html_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "_log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    input_doc_path = FIRST_10_PAGES\n",
    "    output_dir = Path(\"scratch_table\")\n",
    "\n",
    "    doc_converter = DocumentConverter()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    doc_filename = conv_res.input.file.stem\n",
    "\n",
    "    # Export tables\n",
    "    for table_ix, table in enumerate(conv_res.document.tables):\n",
    "        table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "\n",
    "        # Save the table as csv\n",
    "        element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n",
    "        _log.info(f\"Saving CSV table to {element_csv_filename}\")\n",
    "        table_df.to_csv(element_csv_filename)\n",
    "\n",
    "        # Save the table as html\n",
    "        element_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n",
    "        _log.info(f\"Saving HTML table to {element_html_filename}\")\n",
    "        with element_html_filename.open(\"w\") as fp:\n",
    "            fp.write(table.export_to_html())\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup llm\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embedding model\n",
    "# https://docs.llamaindex.ai/en/stable/examples/embeddings/ollama_embedding/\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "#embed_model = OllamaEmbedding(model_name=\"nomic-embed-text:latest\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Settings Configuration\n",
    "In LlamaIndex, you can define global settings so you don't have to pass the LLM / embedding model objects everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "\n",
    "#reader = DoclingReader()\n",
    "reader = DoclingReader(DocumentConverter = doc_converter_global)\n",
    "node_parser = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reader.load_data(SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_parser.get_nodes_from_documents??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nodes from documents\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Display the number of nodes extracted\n",
    "print(f\"Number of nodes extracted: {len(nodes)}\")\n",
    "\n",
    "\n",
    "# Iterate over each node to print its text and metadata\n",
    "for index, node in enumerate(nodes, start=1):\n",
    "    print(f\"\\nNode {index}:\")\n",
    "    print(\"Text:\")\n",
    "    print(node.text)\n",
    "    print(\"Metadata:\")\n",
    "    print(node.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VectorStoreIndex.from_documents??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/data_connectors/DoclingReaderDemo/\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    transformations=[node_parser],\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"In how many countries does KONE operate ?\"\n",
    "result = index.as_query_engine(llm=llm).query(QUERY)\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "# Prettify the output using Rich\n",
    "console = Console()\n",
    "\n",
    "console.print(\n",
    "    Panel(f\"{QUERY}\".replace(\"{text}\", QUERY), title=\"Prompt\", border_style=\"bold red\")\n",
    ")\n",
    "console.print(\n",
    "    Panel(result.response.strip(), title=\"Generated Content\", border_style=\"bold green\")\n",
    ")\n",
    "\n",
    "#print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n",
    "display([(n.text, n.metadata) for n in result.source_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your list of queries\n",
    "queries = [\n",
    "    \"In how many countries does KONE operate?\", #2\n",
    "    \"What is the share of landfill waste at KONE's manufacturing units in 2023?\", #67\n",
    "    \"What is the plastics and rubbers content in monospace 700 dx elevator?\", #25\n",
    "    \"What are the ways to win areas ?\", #12\n",
    "    \"Who is the CEO of KONE?\" #4\n",
    "]\n",
    "\n",
    "# Initialize the query engine\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "# Iterate over each query, process it, and print the results\n",
    "for query in queries:\n",
    "    result = query_engine.query(query)\n",
    "    print(f\"Q: {query}\\nA: {result.response.strip()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
